%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Christopher Latina at 2015-09-28 13:28:05 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{Brent2009,
	Abstract = {A set of low level and cepstral feature extraction externals for pure data (Pd) are introduced and evaluated in a percussion instrument classi cation problem. Because this set of tools is intended for immediate real-time timbre identi - cation using an accompanying classi cation external, a constraint of reporting results within 30 ms after a detected onset is applied. While Bark-frequency cepstrum is the most e ective single feature, it is shown that combining several simple measures into a feature vector produces useful results as well. Temporally evolving feature data collected by taking a series of successive analysis snapshots rather than a single snapshot immediately after onset detection is also discussed.},
	Author = {Brent, William},
	Date-Modified = {2015-09-28 17:27:23 +0000},
	File = {:Users/chrislatina/Library/Application Support/Mendeley Desktop/Downloaded/Brent - 2009 - Cepstral analysis tools for percussive timbre identification.pdf:pdf},
	Journal = {Proceedings of the 3rd International Pure \ldots},
	Keywords = {cepstrum mfcc barks timbre},
	Title = {{Cepstral Analysis Tools for Percussive Timbre Identification}},
	Url = {http://www.williambrent.conflations.com/papers/features.pdf},
	Year = {2009},
	Bdsk-Url-1 = {http://www.williambrent.conflations.com/papers/features.pdf}}

@article{Dc2011,
	Author = {Brent, William},
	Date-Modified = {2015-09-28 17:28:02 +0000},
	File = {:Users/chrislatina/Library/Application Support/Mendeley Desktop/Downloaded/Dc - 2011 - a Perceptually Based Onset Detector for Real-Time and Offline Audio Parsing.pdf:pdf},
	Number = {August},
	Pages = {284--287},
	Title = {{A Perceptually Based Onset Detector for Real-Time and Offline Audio Parsing}},
	Year = {2011}}

@article{Dobrian2004,
	Abstract = {In a realtime interactive work for live performer and computer, the immanently human musical expression of the live performer is not easily equalled by algorithmically generated artificial expression in the computer sound. In cases when we expect the computer to display interactivity in the context of improvisation, pre-programmed emulations of expressivity in the computer are often no match for the charisma of an experienced improviser. This article proposes to achieve expressivity in computer sound by ``stealing'' expressivity from the live performer. By capturing, analyzing, and storing expressive characteristics found in the audio signal received from the acoustic instrument, the computer can use those same characteristic expressive sound gestures, either verbatim or with modifications. This can lead to a more balanced sense of interactivity in works for live performer and computer. },
	Author = {Dobrian, Christopher},
	File = {:Users/chrislatina/Documents/GeorgiaTech/F15/7100/Papers/10.1.1.323.6885.pdf:pdf},
	Journal = {Proceedings of the Sound and Music Computing Conference},
	Title = {{Strategies for Continuous Pitch and Amplitude Tracking in Realtime Interactive Improvisation Software}},
	Year = {2004}}

@article{SettelAuthor1994,
	Abstract = {The fast Fourier transform (FFT) is a powerful general-purpose algorithm widely used in signal analysis. FFTs are useful when the spectral information of a signal is needed, such as in pitch tracking or vocoding algorithms. The FFT can be combined with the inverse fast Fourier transform (IFFT) in order to re-synthesize signals based on its analysis. This application of the FFT/IFFT is of great interest in electroacoustic music because it allows for a high degree of control of a given signal's spectral information, an important aspect of timbre, allowing for flexible and efficient implementation of signal processing algorithms. Real-time implementations of the FFT and IFFT are of particular interest since they may be used to provide musicians with highly responsive and straightforward means for generating and controlling sound in live performance situations. This paper presents musical applications using the IRCAM Signal Processing Workstation (ISPW) that make use of FFT/IFFT-based re-synthesis for timbral transformation in real time. An intuitive and straightforward user interface, intended for use by musicians, has been developed by the authors in the Max programming environment. Techniques for filtering, cross-synthesis, noise reduction, dynamic spectral shaping, and resynthesis are presented along with control structures that allow for fine timbral modification and control of complex sound transformations using few parameters. Emphasis is also placed on developing control structures derived from real-time analysis---time and frequency domain---of a musician's input. The ideas and musical applications discussed in this paper offer composers an intuitive approach to timbral transformation in electroacoustic music and new possibilities in the domain of live signal processing that promise to be of general interest to musicians.},
	Author = {{Settel (Author)}, Zack and {Lippe (Author)}, Cort},
	File = {:Users/chrislatina/Documents/GeorgiaTech/F15/7100/Papers/FFT\_NEWLONDON95.pdf:pdf},
	Journal = {Collected Work: The human touch. Pages: 338-343. (AN: 1994-17738).},
	Keywords = {68: Theory, analysis, and composition -- Computer ,electronic music and computer music -- composition,electronic sound generation -- signal analysis -- ,performance practice--by topic -- electronic music},
	Title = {{Real-time musical applications using FFT-based resynthesis}},
	Url = {http://search.ebscohost.com/login.aspx?direct=true\&db=rih\&AN=1994-17822\&site=ehost-live$\backslash$nhttp://quod.lib.umich.edu/cgi/p/pod/dod-idx/realtime-musical-applications-using-fft-based-resynthesis.pdf?c=icmc$\backslash$nidno=bbp2372.1994.087},
	Year = {1994},
	Bdsk-Url-1 = {http://search.ebscohost.com/login.aspx?direct=true%5C&db=rih%5C&AN=1994-17822%5C&site=ehost-live$%5Cbackslash$nhttp://quod.lib.umich.edu/cgi/p/pod/dod-idx/realtime-musical-applications-using-fft-based-resynthesis.pdf?c=icmc$%5Cbackslash$nidno=bbp2372.1994.087}}

@article{Nystrom2011,
	Abstract = {The concepts introduced by Smalley in the context of space-form (2007) have firmly put acousmatic music on a discourse of spatial exploration, holding much potential for the developing of aesthetics in new directions. This article approaches space from the low level of musical structure, with a multi-dimensional attitude to space-form, exploring spatial texture, a concept introduced by Smalley to describe the temporal formations of space in spectromorphology (1997). Spatial articulation is investigated in the context of granular-oriented textures, proposing a micro-spatial, perceptual morphology ‚\"{A}\`{\i} the texton ‚\"{A}\`{\i} as an aesthetic approach to acousmatic music. This follows Albert Bregman's speculation regarding equivalents to visual perception in texture, where the theory of textons was first developed by the neuroscientist B√{\copyright}la Julesz.The article discusses acousmatic textons, in terms of intrinsic properties, the way they propagate in time, and how they organise in distributions to form spatial textures. The emergent macroscopic qualities of textonal formations are also reflected upon in the introduction of a group of textural states, where source-bonded spaces and abstract musical thinking coalesce.},
	Author = {Nystr\"{o}m, Erik},
	Doi = {10.1017/S1355771810000397},
	File = {:Users/chrislatina/Documents/GeorgiaTech/F15/7100/Papers/Textons\_and\_the\_Propagation\_of\_Space.pdf:pdf},
	Isbn = {1355-7718},
	Issn = {1355-7718},
	Journal = {Organised Sound},
	Number = {01},
	Pages = {14--26},
	Title = {{Textons and the Propagation of Space in Acousmatic Music}},
	Volume = {16},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/S1355771810000397}}

@article{Waters2007,
	Author = {Waters, S},
	File = {:Users/chrislatina/Documents/GeorgiaTech/F15/7100/Papers/PerformEcosystems.pdf:pdf},
	Journal = {EMS: Electroacoustic Music Studies Network},
	Pages = {1--20},
	Title = {{Performance Ecosystems: Ecological approaches to musical interaction}},
	Url = {http://webuser.fh-furtwangen.de/~friedm/PerformEcosystems.pdf},
	Year = {2007},
	Bdsk-Url-1 = {http://webuser.fh-furtwangen.de/~friedm/PerformEcosystems.pdf}}
